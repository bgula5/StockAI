{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense, Dropout\nfrom keras.callbacks import EarlyStopping\nfrom sklearn.metrics import mean_squared_error\nimport matplotlib.pyplot as plt\n\ndf = pd.read_csv(r'C:\\Data\\NVDA.csv')\n\nwindow = 20\ndf['MA'] = df['Close'].rolling(window=window).mean()\ndf['STD'] = df['Close'].rolling(window=window).std()\ndf['UpperBand'] = df['MA'] + (2 * df['STD'])\ndf['LowerBand'] = df['MA'] - (2 * df['STD'])\n\ndelta = df['Close'].diff()\ngain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\nloss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\nrs = gain / loss\ndf['RSI'] = 100 - (100 / (1 + rs))\ndf['Volume_MA'] = df['Volume'].rolling(window=window).mean()\ndf['Volume_STD'] = df['Volume'].rolling(window=window).std()\ndf['Volatility'] = df['Close'].rolling(window=window).std()\n\nfeatures = ['Close', 'UpperBand', 'LowerBand', 'RSI', 'Volume_MA', 'Volume_STD', 'Volatility']\ntarget = 'Close'\n\ndf['Target'] = df['Close'].shift(-1)\ndf.dropna(inplace=True)\n\nscaler = MinMaxScaler(feature_range=(0, 1))\ndf[features] = scaler.fit_transform(df[features])\n\n\ndef create_sequences(data, seq_length):\n    sequences = []\n    targets = []\n    for i in range(len(data) - seq_length):\n        sequences.append(data.iloc[i:i + seq_length][features].values)\n        targets.append(data.iloc[i + seq_length][target])\n    return np.array(sequences), np.array(targets)\n\n\nsequence_length = 10\n\nX, y = create_sequences(df, sequence_length)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nmodel = Sequential()\nmodel.add(LSTM(units=32, return_sequences=True, input_shape=(X_train.shape[1], len(features))))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(units=32))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(units=1))\n\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n\nhistory = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n\ny_pred = model.predict(X_test)\n\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))\nprint(\"Root Mean Squared Error (RMSE):\", rmse)\n\nplt.figure(figsize=(10, 6))\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\nplt.figure(figsize=(12, 6))\nplt.plot(y_test, label='Actual Closing Prices', color='blue')\nplt.plot(y_pred, label='Predicted Closing Prices', color='red')\nplt.title('Actual vs Predicted Closing Prices')\nplt.xlabel('Time')\nplt.ylabel('Closing Price')\nplt.legend()\nplt.show()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}